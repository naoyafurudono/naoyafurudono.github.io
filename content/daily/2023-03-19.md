---
title: "2023-03-19"
date: 2023-03-19T10:46:59+09:00
author: "Naoya Furudono"
draft: false
tags: [
    "daily"
    ,"PL"
    ,"tech"
    ,"idea"
]
---

最近AIが流行っていて、精度がすごいと話題で、生活が多かれ少なかれ変わっていくのだろうなという感じがする。
ああいう機械学習ベースのAIは学習で直感を鍛えて、それに基づく出力をするものだと僕は解釈している。
人間が頭を使うときには直感を論理とか議論で検証して、主張の穴を見つけて改善するサイクルを回すはずだ。
今の機械学習っぽいAIは直感で得た主張を論理で解釈しないだろう（[NECがそういうことを考えていそう](https://www.nec.com/en/global/rd/technologies/201807/index.html)。
それができればAIはもっとつよくなるはずだし、そういうAIを見てみたい。

実現するためにはAIの入出力に使う「言語」に解釈を入れることと、それをもとにして論証を行うことが必要だろう。
今のAIは抽象構文木を操作の対象にしていて、それを意味を解釈するようにしたらいいんじゃないかという想像だ。

今ある論理が世の中の事象を扱うのに十分かはわからないし、多分結構不足しているはずだ。
機械学習AIのための論理体系の研究とかあったら楽しいだろう。NIIとかでやってないだろうか？

